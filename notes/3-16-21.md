# Real attempted run through

Petrosino sent more detailed methods paper that has instructions
for the pipeline use. Going to walk through those today as they should
use the test data provided.

[Link to Paper](https://pubmed.ncbi.nlm.nih.gov/33111111/)

Note test data is for yeast so need to confirm what the human sequencing
primers used are the same as yeast primers (adapters sorry). 

## Bedfiles in `targets.txt`

Looks like these are optional and would not be required to run the pipeline

```
Optional: The user can include up to 3 BED files containing coordinates for the expected
breaks. As a default and for the purpose of the test dataset, GLOE-Pipe will use the expected
breaks for BsrDI, Nb.BsrDI and NotI:
```

## Download dependencies through conda

Setup conda env to put most of the programs needed. Also needed to
download trimmomatic binary since the pipeline basically insists on having
that.

```
wget http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/Trimmomatic-0.36.zip
```

Looks like that got deleted somehow so moving to software and changing
the trimmomatic dependency to not be dependent on the other tools folder.

## Download Bowtie2 yeast index

```
wget https://genome-idx.s3.amazonaws.com/bt/R64-1-1.zip
```

## Download chromosome sizes file

```
wget https://hgdownload-test.gi.ucsc.edu/goldenPath/sacCer3/bigZips/sacCer3.chrom.sizes
```

## Change adapter path

Got this error

```
TrimmomaticSE: Started with arguments:
 -phred33 -threads 4 test_data/NbBsrDI_NotI_1_10_rep1.fastq.gz /home/ethollem/projects/test_GLOE_pipe/rawdata_trimmed/NbBsrDI_NotI_1_10_rep1_trimmed.fastq.gz ILLUMINACLIP:.../TruSeq3-SE.fa:2:30:10 SLIDINGWINDOW:4:15 MINLEN:36
```

So changed adapter path in variables file.

## Changed tools versions

Changed tool versions in `tool.versions.groovy` to `""` as works more
reliably then giving a specific version.


## Bowtie2 errors

Ran pipeline and got 

```
Module bowtie2/2.2.6 loaded 
Module samtools/1.2 loaded 
Error: reads file does not look like a FASTQ file
```

Not sure what file is actually being handed off to the pipeline here.

Went into the `.bpipe` log directory and found this was the command that
was executed to run bowtie2

```
module load bowtie2/ && module load samtools/ &&             if [ -n "$SLURM_JOBID" ]; then                 export TMPDIR=/jobdir/${SLURM_JOBID};             fi                                       &&               bowtie2   -p4  -x /home/ethollem/projects/test_GLOE_pipe/genome/R64-1-1/R64-1-1 /home/ethollem/projects/test_GLOE_pipe/rawdata_trimmed/NbBsrDI_rep2_trimmed.fastq.gz | samtools view -bhSu - | samtools sort -O bam -@4 -T $TMPDIR/$(basename /home/ethollem/projects/test_GLOE_pipe/mapped/NbBsrDI_rep2_trimmed)_bowtie2_sorted - > /home/ethollem/projects/test_GLOE_pipe/mapped/NbBsrDI_rep2_trimmed_bowtie2_sorted.bam &&             samtools view -q 30 -bhu /home/ethollem/projects/test_GLOE_pipe/mapped/NbBsrDI_rep2_trimmed_bowtie2_sorted.bam | samtools sort -@4 -T $TMPDIR/$(basename /home/ethollem/projects/test_GLOE_pipe/mapped/NbBsrDI_rep2_trimmed) -o /home/ethollem/projects/test_GLOE_pipe/mapped/NbBsrDI_rep2_trimmed.bam &&             rm /home/ethollem/projects/test_GLOE_pipe/mapped/NbBsrDI_rep2_trimmed_bowtie2_sorted.bam
```

The key being `bowtie2   -p4 ` which may be causing the error due to lack of space
between `-p` and `4`. 

So I modified `bowtie2.vars.groovy` and added extra space at end of `-p` arg.

Then reran and it sort of paused? Reran again and got these types of errors
similar to what observed before

```
(ERR): bowtie2-align exited with value 134
WARNING: $PATH does not agree with $PATH_modshare counter. The following directories' usage counters were adjusted to match. Note that this may mean that module unloading may not work correctly.
 /share/apps/Trimmomatic-0.36/ /home/ethollem/anaconda3/envs/GLOEPipe/bin
Module bowtie2/2.2.6 loaded 
Module samtools/1.2 loaded 
Error: reads file does not look like a FASTQ file
terminate called after throwing an instance of 'int'
Aborted (core dumped)
(ERR): bowtie2-align exited with value 134
```

Ran bowtie command directly and `-p4` does **not** effect the output.

```
bowtie2   -p 4  -x /home/ethollem/projects/test_GLOE_pipe/genome/R64-1-1/R64-1-1 /home/ethollem/projects/test_GLOE_pipe/rawdata_trimmed/NbBsrDI_rep2_trimmed.fastq.gz
```

Also got this guy 

```
WARNING: $PATH does not agree with $PATH_modshare counter. The following directories' usage counters were adjusted to match. Note that this may mean that module unloading may not work correctly.
 /share/apps/Trimmomatic-0.36/ /home/ethollem/anaconda3/envs/GLOEPipe/bin
```

Not sure where `/share/apps` is coming from.


## Stage bam2BedI

This is the stage of the pipeline which calls perl script. Seems like it is
trying to call kentUtils which is not listed as a dependency and I am not
sure what it is actually used for. In any case produces these messages
to the terminal

```
ERROR: Unable to locate a modulefile for 'kentUtils/v365'
ERROR: Unable to locate a modulefile for 'kentUtils/v365'
ERROR: Unable to locate a modulefile for 'kentUtils/v365'
ERROR: Unable to locate a modulefile for 'kentUtils/v365'
ERROR: Unable to locate a modulefile for 'kentUtils/v365'
ERROR: Unable to locate a modulefile for 'kentUtils/v365'
ERROR: Unable to locate a modulefile for 'kentUtils/v365'
```

Assuming one for each job it is trying to complete.

At the same time the pipeline seems to have stalled? Waiting to see what
happens here. There is nothing listed by `squeue` and the `bpipe.log` file
continues to just produce the same repeated output over and over and kind of
seems like it is stuck in some kind of loop.

```
bpipe.executor.TorqueStatusMonitor	[27]	WARNING	|12:16:11 Error occurred in processing torque output: java.io.IOException: Cannot run program "qstat": error=2, No such file or directory 
bpipe.Concurrency	[41]	INFO	|12:16:12 Waiting for 1 parallel stages to complete (pool.active=7 pool.tasks=14) 
bpipe.Concurrency	[42]	INFO	|12:16:12 Waiting for 1 parallel stages to complete (pool.active=7 pool.tasks=14) 
bpipe.Concurrency	[40]	INFO	|12:16:12 Waiting for 1 parallel stages to complete (pool.active=7 pool.tasks=14) 
bpipe.Concurrency	[39]	INFO	|12:16:12 Waiting for 1 parallel stages to complete (pool.active=7 pool.tasks=14) 
bpipe.Concurrency	[37]	INFO	|12:16:12 Waiting for 1 parallel stages to complete (pool.active=7 pool.tasks=14) 
bpipe.Concurrency	[43]	INFO	|12:16:12 Waiting for 1 parallel stages to complete (pool.active=7 pool.tasks=14) 
bpipe.Concurrency	[38]	INFO	|12:16:12 Waiting for 1 parallel stages to complete (pool.active=7 pool.tasks=14) 
bpipe.Utils	[75]	INFO	|12:16:14 Executing command: qstat -x 910171 910172 910173 910174 910175 910176 910177 
```

Over and over again. Seems to be unable to get past this kentutils thing.

Just as a test did a find `module load kentUtils/${KENTUTILS_VERSION} &&`
and replaced with echo "hello kent" && to see if that would change anything.

This produces 

```
hello kent
Module samtools/1.2 loaded 
Module bedtools/2.25 loaded
``` 

When running the effected rules. But based on what I am seeing in the log file
it is not changing behavior of the pipeline and I cannot tell what is running.

Maybe I am just being impatient? I am just going to let that run for a while.
Left to do its thing at 12:37 PM. Line count of `bpipe.log` is at 6827. 

Line count at 1:11 pm: 10719

Line count at 1:42: 14043

Seems like this is looping somehow. Maybe failing in a weird way and trying
to reattempt in some way?

Stopped and restarted the pipeline and got a bunch of error that looked like
this one

```
ERROR: stage rfd failed: 

     An attempt was made to assign to global variable RFD_FLAGS after your pipeline already 
     started running. To ensure thread safety, global variables may only be assigned 
     before the pipeline starts. Solutions include:

      - add 'def', 'var', or 'requires' before this assignment to define a local variable,
        eg: def RFD_FLAGS = "--numberOfProcessors 4" or: var RFD_FLAGS : "--numberOfProcessors 4"
      - define a branch variable using: branch.RFD_FLAGS = "--numberOfProcessors 4"

     You can disable this behavior at your own risk by setting allowGlobalWrites=true in 
     your bpipe.config file.
```
also right after

```
ERROR: Unable to locate a modulefile for 'deepTools'
ERROR: Unable to locate a modulefile for 'deepTools'
```
These errors seem to be occurring at the ` Stage rfd (2) `. 

### RDD stage

Changed `"module load deepTools/${DEEPTOOLS_VERSION}` to 
`echo "module load deepTools/${DEEPTOOLS_VERSION}"` to see if not loading the
module was causing stalling.

This seemed to move things along but produced the error below

```
bigwigCompare: error: argument --outFileName/-o: /home/ethollem/projects/test_GLOE_pipe/tracks/strandspecific/rfd/test_GLOE_pipe.1kb.rfd.rev-fwd.bw

usage: bigwigCompare [-h] [--version] [--binSize INT bp]
                     [--region CHR:START:END]
                     [--blackListFileName BED file [BED file ...]]
                     [--numberOfProcessors INT] [--verbose] --outFileName
                     FILENAME [--outFileFormat {bigwig,bedgraph}]
                     [--deepBlueURL DEEPBLUEURL] [--userKey USERKEY]
                     [--deepBlueTempDir DEEPBLUETEMPDIR] [--deepBlueKeepTemp]
                     --bigwig1 Bigwig file --bigwig2 Bigwig file
                     [--scaleFactors SCALEFACTORS] [--pseudocount PSEUDOCOUNT]
                     [--ratio {log2,ratio,subtract,add,mean,reciprocal_ratio,first,second}]
                     [--skipNonCoveredRegions]
bigwigCompare: error: argument --outFileName/-o: /home/ethollem/projects/test_GLOE_pipe/tracks/strandspecific/rfd/test_GLOE_pipe.1kb.rfd.rev-fwd.bw file can't be opened for writing
```

Probably because `test_GLOE_pipe.1kb.rfd.rev-fwd.bw` does not exist.

I then deleted all output files and just ran everything again.



Reran after adding `allowGlobalWrites=true` to config file.






